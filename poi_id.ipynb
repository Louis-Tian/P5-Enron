{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Report\n",
    "In this section, I will directly answer the questions that is required for completing this project. The detailed documentation is also included after this section.\n",
    "\n",
    "#### Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. As part of your answer, give some background on the dataset and how it can be used to answer the project question. Were there any outliers in the data when you got it, and how did you handle those?  [relevant rubric items: “data exploration”, “outlier investigation”]\n",
    "\n",
    "The learning problem at hand is to identifying POIs based on a set of predefined features about individuals. This is precisely what machine learning is trying to achieve, learning from existing data and try to make accurate predictions from the unseen. This POI identification problem is a typical binary classification problem. Some common algorithm used in dealing with this type of problem include:\n",
    "* Logistic Regression\n",
    "* Decision Tree (including Random Forest, Adaboosting Decision Tree)\n",
    "* Support Vector Machine\n",
    "* Naive Bayes\n",
    "\n",
    "The dataset given includes 145 rows and 20 features (excluding names). It's generated base on two separate sources of information, a financial dataset and the famous Enron Email Corpus dataset. It is relatively easy to see how those data might be helpful. For example, it would be reasonable to assume that POIs tends to be within a social circle and hence must communicate to each other quite often. \n",
    "\n",
    "Other than the \"TOTAL\" row (which I simply drop it from the dataset), I didn't find any obvious outlier. The dataset did however has a lot of missing value (NaNs). I handled this missing value by filling the missing value with either 0 or featuren median depends on whether the features is a financial or email feature. The rationale of which is quite lengthy and can be find in the `understand the dataset` section\n",
    "\n",
    "#### What features did you end up using in your POI identifier, and what selection process did you use to pick them? Did you have to do any scaling? Why or why not? As part of the assignment, you should attempt to engineer your own feature that does not come ready-made in the dataset -- explain what feature you tried to make, and the rationale behind it. (You do not necessarily have to use it in the final analysis, only engineer and test it.) In your feature selection step, if you used an algorithm like a decision tree, please also give the feature importances of the features that you use, and if you used an automated feature selection function like SelectKBest, please report the feature scores and reasons for your choice of parameter values.  [relevant rubric items: “create new features”, “properly scale features”, “intelligently select feature”]\n",
    "My final list of features includes the following: 'salary', 'bonus', 'pct_msg_with_poi', 'total_stock_value', 'expenses', 'exercised_stock_options', 'deferred_income', 'short_term_incomes', and 'long_term_incentive'. \n",
    "\n",
    "I first manually picked six features which I believe will be important based on my reading about the scandal. Then I used a K-Best algorithm generate another list of top six features. \n",
    "    - KBest Feature Score - \n",
    "    exercised_stock_options    25.380102\n",
    "    total_stock_value          24.752531\n",
    "    bonus                      21.327894\n",
    "    salary                     18.861776\n",
    "    deferred_income            11.732698\n",
    "    long_term_incentive        10.222905\n",
    "\n",
    "The final list is the combination of the both.\n",
    "\n",
    "I engineered two features:\n",
    "\n",
    "* __`short_term_incomes`__ I intuitive believe this could be important, as I expect POIs to receive a lot of short term income, regardless in what form.\n",
    "\n",
    "* __`pct_msg_with_poi`__ I created this by combining the four original email features. The idea is to measures how closely someone is within the POI 'circle'. If someone is within the POI circle, then he/she must both send and receive a larger proportion of email from POI than those, not in the circle.\n",
    "\n",
    "I preprocessed the data by using StandardScaler when using the following algorithm\n",
    "1. Support Vector Classifier (scaling is required as SVM is not scale invariant).\n",
    "2. Logistic Regression (scaling is used because I also used PCA, which is not scaled invariant)\n",
    "\n",
    "#### What algorithm did you end up using? What other one(s) did you try? How did model performance differ between algorithms?  [relevant rubric item: “pick an algorithm”]\n",
    "I have tried following algorithms:\n",
    "    * Simple Decision Tree\n",
    "    * Random Forest \n",
    "    * Adaboosting Decision Tree\n",
    "    * Logit Regression\n",
    "    * Support Vector Machine\n",
    "    * Naive Bayes\n",
    "    \n",
    "I selected Random Forest to be the final algorithm because it performed significantly better than other algorithm and the performance is very consistent across training and validation dataset. \n",
    "\n",
    "#### What does it mean to tune the parameters of an algorithm, and what can happen if you don’t do this well?  How did you tune the parameters of your particular algorithm? (Some algorithms do not have parameters that you need to tune -- if this is the case for the one you picked, identify and briefly explain how you would have done it for the model that was not your final choice or a different model that does utilize parameter tuning, e.g. a decision tree classifier).  [relevant rubric item: “tune the algorithm”]\n",
    "\n",
    "##### What is tuning? What is the main goal of tuning a classifier? #####\n",
    "\n",
    "Parameter tuning is the process of testing/validating models under different hyperparameters.\n",
    "\n",
    "Using Probably Approximately Correct Learning's terminology, machine learning can be fundamentally decomposed into two subtasks, learning the concept model class and learning the best concept within the class.\n",
    "* The first step is about forming a hypothesis about concept class, a family of possible models. The different algorithm corresponding to different concept class and hence model selection is about finding the best concept class. \n",
    "* Given any concept class, we also need to find the best concept for the class, that is the role of parameter tuning.\n",
    "\n",
    "To understand this, let's suppose we observed some points on a 2-d plane. Those points lie on an unknown geometric shape which we would like to find out. The first step toward finding this shape of interest is to make hypotheses about the class of the shape, whether it is a circle, a polygon or a polynominal etc. This is model selection. Let's say the concept class is polynominals, then we can ask what's the degree of this polynominal? The process of determine this is parameter tuning. Once the degree of polynominal is determined, the process of finding the polynominal coefficients is what we called fitting the model. The entire learning process is about trying different models and hyperparameters to find the one that best explains our observations.\n",
    "\n",
    "A machine learning must perform all steps above to achieve good learning. Failure at any step will lead to bad classifiers.\n",
    "\n",
    "##### Is there any possibility for us to over- or under-tune a classifier? What could go wrong if we tune a classifier aiming prediction scores on top of training data?\n",
    "Yes, one can easily over or under-tune a classifier.\n",
    "\n",
    "Using our previous example, suppose the true shape of interest is a polynomial of degree 4. If one under-tunes a classifier by only testing a polynomial of degree 1 (linear regression), then the final classifier is very likely to have poor performance.\n",
    "\n",
    "One the other hand, without a proper validation strategy, one can easily over-tune a classifier. On fact, without validating the models on a different dataset, there will be no difference between a hyperparameter and a parameter. Again using our previous example, let's assume we have decided to tune the hyperparameter by considering the case where the ploynominal is of degree one ( $y = a + bx$ ) or two ( $ y = a + bx + c^2$ ). If both fitting and tuning are done on the same dataset, then the entire process will be equivalent to fitting the higher order function $y = d(a + bx) + (1-d)(a + bx + c^2)\\ where\\ d \\in \\{0, 1\\} $. In this higher order function the degree of polynominal becames a parameter. Hence, without a good validation stragety, one can overfit a hyperparameter just like overfit a parameter.\n",
    "\n",
    "##### How did you tune the parameters of your particular algorithm?\n",
    "I used `GridSearchCV` to systematically tune the parameters on all of the algorithms (except Naive Bayes which don't have any parameter to be tuned).\n",
    "\n",
    "#### What is validation, and what’s a classic mistake you can make if you do it wrong? How did you validate your analysis?  [relevant rubric item: “validation strategy”]\n",
    "A good machine learning algorithm must generalise. Meaning it must performance equally well on data that it haven't seen before. Validation is the step of testing the algorithm on an unseen dataset to ensure it generalises. The classic mistake is to train and validate an overfitted model based on the same set of data. \n",
    "\n",
    "Following common practise, I will split the data into two set, training and validation. The training data set is used in conjunction with cross-validation to find the best parameter and hyperparameter. Once the model is training and tuned, then it is validated using the validation dataset. I compare the performance of the model using the two different datasets to assess how well the model generalise. \n",
    "\n",
    "#### Give at least two evaluation metrics and your average performance for each of them.  Explain an interpretation of your metrics that says something human-understandable about your algorithm’s performance. [relevant rubric item: “usage of evaluation metrics”]\n",
    "\n",
    "The following is the performance metrics of my final random forest algorithm on the validation dataset.\n",
    "\n",
    "                 precision    recall  f1-score   support\n",
    "\n",
    "          False      1.000     0.795     0.886        39\n",
    "           True      0.385     1.000     0.556         5\n",
    "\n",
    "    avg / total      0.930     0.818     0.848        44\n",
    "    \n",
    "The recall on positive label is 1.0, meaning all the classifier identified all of the positive labels in the validation set. (correctly identified all of the POI in the test dataset)\n",
    "\n",
    "The precision of 0.385 on positive means the among all of the predicted positive, around 38.5% of them are correct (true postive). So by combining the two, when the classifier predicts someone to be POI, we can say we are 38.5% confident he/she is a POI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Details of Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand the Question\n",
    "\n",
    "#### Summarize for us the goal of this project and how machine learning is useful in trying to accomplish it. \n",
    "\n",
    "The learning problem at hand is identify person of interest based on the given dataset. This exactly what machine learning trying to achieve, learning from existing data and try to make accurate prediction for unseem. The POI idenfication is a binary classification problem. Some typical algorithm used in dealing with this type of problem include:\n",
    "\n",
    "* Logistic Regression\n",
    "* Decision Tree (including Random Forest, Adaboosting Decision Tree)\n",
    "* Support Vector Machine\n",
    "* Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./final_project_dataset.pkl', 'r') as fd:\n",
    "    df = pd.DataFrame.from_dict(pickle.load(fd), orient='index')\\\n",
    "            .replace(['NaN'], np.nan)\\\n",
    "            .drop(['email_address'], axis='columns')\n",
    "\n",
    "labels = df['poi'].astype(bool)\n",
    "features = df.drop('poi', axis=1).astype(np.float32)\n",
    "\n",
    "df = pd.concat([labels, features], axis=1)\n",
    "\n",
    "df = df.drop('TOTAL') # drop the total row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of data points and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows: 145\n",
      "\n",
      "# of features: 20\n",
      "    - # of email features: 5\n",
      "    - # of financial features: 15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "email_features = ['to_messages', 'from_messages', 'from_this_person_to_poi', 'from_poi_to_this_person', 'shared_receipt_with_poi']\n",
    "financial_features = list(set(df.columns) - set(email_features))\n",
    "\n",
    "print '# of rows: {}'.format(df.shape[0])\n",
    "print '''\n",
    "# of features: {}\n",
    "    - # of email features: {}\n",
    "    - # of financial features: {}\n",
    "'''.format(df.shape[1], len(email_features), len(financial_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 146 data points and 20 features (excluding names)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Allocation across classes (POI/non-POI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    127\n",
      "True      18\n",
      "Name: poi, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print df['poi'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is highly unbalance. Only 18 examples are labelled as POI, vs 128 Non-POI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 145 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 15 columns):\n",
      "salary                       94 non-null float32\n",
      "deferral_payments            38 non-null float32\n",
      "total_payments               124 non-null float32\n",
      "exercised_stock_options      101 non-null float32\n",
      "bonus                        81 non-null float32\n",
      "director_fees                16 non-null float32\n",
      "restricted_stock_deferred    17 non-null float32\n",
      "total_stock_value            125 non-null float32\n",
      "expenses                     94 non-null float32\n",
      "loan_advances                3 non-null float32\n",
      "other                        92 non-null float32\n",
      "poi                          145 non-null bool\n",
      "long_term_incentive          65 non-null float32\n",
      "restricted_stock             109 non-null float32\n",
      "deferred_income              48 non-null float32\n",
      "dtypes: bool(1), float32(14)\n",
      "memory usage: 9.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df[financial_features].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 145 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 5 columns):\n",
      "to_messages                86 non-null float32\n",
      "from_messages              86 non-null float32\n",
      "from_this_person_to_poi    86 non-null float32\n",
      "from_poi_to_this_person    86 non-null float32\n",
      "shared_receipt_with_poi    86 non-null float32\n",
      "dtypes: float32(5)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df[email_features].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of poi with email features: 14\n",
      "# of poi without email features: 4\n",
      "Proportion of poi from individual with email features: 0.163\n",
      "Proportion of poi from individual without email features: 0.068\n"
     ]
    }
   ],
   "source": [
    "poi_with_email_features = ((df['poi'] == True) & (~df['to_messages'].isnull())).sum() \n",
    "poi_without_email_features = ((df['poi'] == True) & (df['to_messages'].isnull())).sum() \n",
    "total_with_email_features = (~df['to_messages'].isnull()).sum() \n",
    "total_without_email_features = (df['to_messages'].isnull()).sum()\n",
    "\n",
    "print '# of poi with email features: {}'.format(poi_with_email_features)\n",
    "print '# of poi without email features: {}'.format(poi_without_email_features)\n",
    "\n",
    "print 'Proportion of poi from individual with email features: {:.3f}'.format(poi_with_email_features / float(total_with_email_features))\n",
    "print 'Proportion of poi from individual without email features: {:.3f}'.format(poi_without_email_features / float(total_without_email_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is created augument the financial information with the email information extracted from Enron Email Corpus dataset. However, the financial information includes not only the Enron's employee but also some external Debtor and non-employee Directors whose email information is not included in Enron Email Corpus dataset. \n",
    "\n",
    "This introduces two kinds of missing value in this dataset. Those NaNs in financial information easily replace by zero. Those in emails features represents lack of information and is more difficult to deal with. \n",
    "\n",
    "As discussed in *Dataset and Questions* lecture, this could introduce some serious bias in our estimator. Out of the 18 POIs in the dataset, 14 has email features. This could leads our estimator to mistake missing email features as a good indicator for predicting POI. \n",
    "\n",
    "However, given the size of our dataset, we would like to preserve as much data as possible. As show in the calculation above, 16.3% of individuals with email features available in the dataset are POI, and only 6.8% of those without. Given the significant difference, there is a good chance of it introducing large bias is small. And for the purpose of this project, I think the most simpliest (yet reasonable) way to dealing with missing value in email features is filling the missing value with features' medium. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[financial_features] = df[financial_features].fillna(0)\n",
    "\n",
    "for feature in email_features:\n",
    "    median = df.loc[~df[feature].isnull(), feature].median(axis='index')\n",
    "    df[feature] = df[feature].fillna(value=median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>145.0</td>\n",
       "      <td>1722.765503</td>\n",
       "      <td>2029.354269</td>\n",
       "      <td>57.0</td>\n",
       "      <td>904.0</td>\n",
       "      <td>1211.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>15149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>145.0</td>\n",
       "      <td>377.758606</td>\n",
       "      <td>1441.885571</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>14368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>145.0</td>\n",
       "      <td>27.710344</td>\n",
       "      <td>78.611656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>145.0</td>\n",
       "      <td>52.731033</td>\n",
       "      <td>68.431428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>145.0</td>\n",
       "      <td>999.072388</td>\n",
       "      <td>930.455534</td>\n",
       "      <td>2.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>740.5</td>\n",
       "      <td>900.0</td>\n",
       "      <td>5521.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count         mean          std   min    25%     50%  \\\n",
       "to_messages              145.0  1722.765503  2029.354269  57.0  904.0  1211.0   \n",
       "from_messages            145.0   377.758606  1441.885571  12.0   36.0    41.0   \n",
       "from_this_person_to_poi  145.0    27.710344    78.611656   0.0    6.0     8.0   \n",
       "from_poi_to_this_person  145.0    52.731033    68.431428   0.0   25.0    35.0   \n",
       "shared_receipt_with_poi  145.0   999.072388   930.455534   2.0  589.0   740.5   \n",
       "\n",
       "                            75%      max  \n",
       "to_messages              1607.0  15149.0  \n",
       "from_messages              52.0  14368.0  \n",
       "from_this_person_to_poi    14.0    609.0  \n",
       "from_poi_to_this_person    41.0    528.0  \n",
       "shared_receipt_with_poi   900.0   5521.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[email_features].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>145.0</td>\n",
       "      <td>1.841671e+05</td>\n",
       "      <td>1.969598e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210500.0</td>\n",
       "      <td>269076.0</td>\n",
       "      <td>1111258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>145.0</td>\n",
       "      <td>2.205579e+05</td>\n",
       "      <td>7.517046e+05</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7961.0</td>\n",
       "      <td>6426990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>145.0</td>\n",
       "      <td>2.243477e+06</td>\n",
       "      <td>8.817821e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91093.0</td>\n",
       "      <td>916197.0</td>\n",
       "      <td>1934359.0</td>\n",
       "      <td>103559792.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>145.0</td>\n",
       "      <td>2.061486e+06</td>\n",
       "      <td>4.781940e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>607837.0</td>\n",
       "      <td>1668260.0</td>\n",
       "      <td>34348384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>145.0</td>\n",
       "      <td>6.713353e+05</td>\n",
       "      <td>1.230147e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>8000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>145.0</td>\n",
       "      <td>9.911489e+03</td>\n",
       "      <td>3.120272e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>145.0</td>\n",
       "      <td>7.291157e+04</td>\n",
       "      <td>1.297470e+06</td>\n",
       "      <td>-1787380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15456290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>145.0</td>\n",
       "      <td>2.889718e+06</td>\n",
       "      <td>6.172223e+06</td>\n",
       "      <td>-44093.0</td>\n",
       "      <td>221141.0</td>\n",
       "      <td>955873.0</td>\n",
       "      <td>2282768.0</td>\n",
       "      <td>49110080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>145.0</td>\n",
       "      <td>3.513137e+04</td>\n",
       "      <td>4.524717e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18834.0</td>\n",
       "      <td>53122.0</td>\n",
       "      <td>228763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>145.0</td>\n",
       "      <td>5.787931e+05</td>\n",
       "      <td>6.771012e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81525000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>145.0</td>\n",
       "      <td>2.952100e+05</td>\n",
       "      <td>1.127403e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>150458.0</td>\n",
       "      <td>10359729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>145.0</td>\n",
       "      <td>3.346341e+05</td>\n",
       "      <td>6.853637e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>374347.0</td>\n",
       "      <td>5145434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>145.0</td>\n",
       "      <td>8.625464e+05</td>\n",
       "      <td>2.010852e+06</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360528.0</td>\n",
       "      <td>698920.0</td>\n",
       "      <td>14761694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>145.0</td>\n",
       "      <td>-1.923475e+05</td>\n",
       "      <td>6.041176e+05</td>\n",
       "      <td>-3504386.0</td>\n",
       "      <td>-36666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count          mean           std        min  \\\n",
       "salary                     145.0  1.841671e+05  1.969598e+05        0.0   \n",
       "deferral_payments          145.0  2.205579e+05  7.517046e+05  -102500.0   \n",
       "total_payments             145.0  2.243477e+06  8.817821e+06        0.0   \n",
       "exercised_stock_options    145.0  2.061486e+06  4.781940e+06        0.0   \n",
       "bonus                      145.0  6.713353e+05  1.230147e+06        0.0   \n",
       "director_fees              145.0  9.911489e+03  3.120272e+04        0.0   \n",
       "restricted_stock_deferred  145.0  7.291157e+04  1.297470e+06 -1787380.0   \n",
       "total_stock_value          145.0  2.889718e+06  6.172223e+06   -44093.0   \n",
       "expenses                   145.0  3.513137e+04  4.524717e+04        0.0   \n",
       "loan_advances              145.0  5.787931e+05  6.771012e+06        0.0   \n",
       "other                      145.0  2.952100e+05  1.127403e+06        0.0   \n",
       "long_term_incentive        145.0  3.346341e+05  6.853637e+05        0.0   \n",
       "restricted_stock           145.0  8.625464e+05  2.010852e+06 -2604490.0   \n",
       "deferred_income            145.0 -1.923475e+05  6.041176e+05 -3504386.0   \n",
       "\n",
       "                                25%       50%        75%          max  \n",
       "salary                          0.0  210500.0   269076.0    1111258.0  \n",
       "deferral_payments               0.0       0.0     7961.0    6426990.0  \n",
       "total_payments              91093.0  916197.0  1934359.0  103559792.0  \n",
       "exercised_stock_options         0.0  607837.0  1668260.0   34348384.0  \n",
       "bonus                           0.0  300000.0   800000.0    8000000.0  \n",
       "director_fees                   0.0       0.0        0.0     137864.0  \n",
       "restricted_stock_deferred       0.0       0.0        0.0   15456290.0  \n",
       "total_stock_value          221141.0  955873.0  2282768.0   49110080.0  \n",
       "expenses                        0.0   18834.0    53122.0     228763.0  \n",
       "loan_advances                   0.0       0.0        0.0   81525000.0  \n",
       "other                           0.0     947.0   150458.0   10359729.0  \n",
       "long_term_incentive             0.0       0.0   374347.0    5145434.0  \n",
       "restricted_stock                0.0  360528.0   698920.0   14761694.0  \n",
       "deferred_income            -36666.0       0.0        0.0          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[financial_features].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything seems to be within reasonable range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- KBest Feature Score - \n",
      "exercised_stock_options    25.380102\n",
      "total_stock_value          24.752531\n",
      "bonus                      21.327894\n",
      "salary                     18.861776\n",
      "deferred_income            11.732698\n",
      "long_term_incentive        10.222905\n",
      "dtype: float32\n",
      "\n",
      "-- Final Features --\n",
      "['salary', 'bonus', 'pct_msg_with_poi', 'total_stock_value', 'expenses', 'exercised_stock_options', 'deferred_income', 'short_term_incomes', 'long_term_incentive']\n"
     ]
    }
   ],
   "source": [
    "# classsification label\n",
    "y = pd.to_numeric(df['poi'])\n",
    "X = df.drop(['poi'], axis='columns')\n",
    "\n",
    "# New feature !!!\n",
    "df['short_term_incomes'] = df[['salary', 'bonus', 'director_fees', 'expenses', 'other', 'exercised_stock_options']].sum(axis=1)\n",
    "df['pct_msg_with_poi'] = (df['from_poi_to_this_person'] + df['from_this_person_to_poi']) / (df['to_messages'] + df['from_messages'])\n",
    "\n",
    "# manual selected features\n",
    "selected_features = ['expenses', 'bonus', 'exercised_stock_options', 'total_stock_value', 'pct_msg_with_poi', 'short_term_incomes']\n",
    "\n",
    "# K-Best features\n",
    "Kbest = SelectKBest(k=6).fit(X, y) # all features \n",
    "X_kbest = Kbest.transform(X)\n",
    "kbest_features = list(pd.Series(index = X.columns, data = Kbest.scores_).sort_values(ascending=False)[0: 6].index)\n",
    "print '- KBest Feature Score - '\n",
    "print pd.Series(index = X.columns, data = Kbest.scores_).sort_values(ascending=False)[0: 6]\n",
    "\n",
    "\n",
    "# Final Features\n",
    "list_of_features = list(set(selected_features) | set(kbest_features)) # combine features\n",
    "X = df.drop(['poi'], axis='columns')[list_of_features]\n",
    "\n",
    "print '\\n-- Final Features --\\n{}'.format(list_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features enginerring\n",
    "__ `short_term_incomes`__\n",
    "\n",
    "I intuitive believe this could be important, as I expect POIs to recieve a lot of short term income, regardless in what form.\n",
    "\n",
    "__`pct_msg_with_poi`__\n",
    "\n",
    "I created one addtional feature `pct_msg_with_poi` by combining the four original email features. The idea is to measures how closely someone is within the POI 'circle'. If some one is within the POI circle then he/she must both send and recieve a larger proportion of email from POI than those not in the circle.\n",
    "\n",
    "I have manually pick 5 features that I believe would be most useful in predicting the POIs based on my reading of Wikipeida page on the Enron scandal. The size of the features are best on \n",
    "\n",
    "#### Manual Feature Selection\n",
    "__`exercised_stock_options` and `total_total_stock_value`__\n",
    "\n",
    "The Enron executives uses deceiving accounting practise to hide debt and losses in order to keep stock price afloat, from which they recieve large benefit from execise stock options and sell stock on hand.\n",
    "\n",
    "__`bonus` and `expenses`__\n",
    "\n",
    "Enron is also critised for its `bonus` chasing cooperate culture, where the employee would chase for unprofitable or even loss making deal in order to recieve sizable cash bonus. And the same time, the CEO Skilling believed that if 'employees were constantly worried about cost, it would hinder original thinking', hence created extravagant expending culture as well. Both directly contributes to the fall of Enron.\n",
    "\n",
    "__`pct_msg_with_poi`__ and __`short_term_incomes`__\n",
    "\n",
    "Of course, I also included this feature, after all I made it for a reason.\n",
    "\n",
    "#### K-Best\n",
    "I have also selected top 6 features using the K-Best algorithm. As it turns out, four out of four features selected using K-Best are the same as my manual select list.\n",
    "\n",
    "### Final List of Features\n",
    "I combined my manual selected features with those from the K-Best to create my final list of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good machine learning algorithm must generalise. Meaning it must performance equally well on data that it haven't seem before. Validation is the step of testing the algorithm on an unseem dataset to ensure it actaully generalise.\n",
    "\n",
    "Following common practise, I will split the data into two set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainning set: (101, 9)\n",
      "test set: (44, 9)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "print 'trainning set:', X_train.shape\n",
    "print 'test set:', X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the goal of the project to have both precision and recall above 0.3, f1, which can be considered as an average of both precision and recall, is considered as the best candidate. for our evaluation metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def report(estimator):\n",
    "    estimator.fit(X_train, y_train)\n",
    "    best = estimator.best_estimator_\n",
    "        \n",
    "    print 'Best estimator:'\n",
    "    print '-' * 60\n",
    "    print best\n",
    "    \n",
    "    print '\\n\\nPerformance on Training Set:'\n",
    "    print '-' * 60\n",
    "    print classification_report(digits=3, y_true=y_train, y_pred=best.predict(X_train))\n",
    "    \n",
    "    print '\\n\\nPerformance on Validation Set:'\n",
    "    print '-' * 60\n",
    "    print classification_report(digits=3, y_true=y_test, y_pred=best.predict(X_test))\n",
    "    \n",
    "    print '\\n\\nPerformance on Entire DataSet:'\n",
    "    print '-' * 60\n",
    "    print classification_report(digits=3, y_true=y, y_pred=best.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# About Tuning Parameters and Model Selection\n",
    "In the following sections, I am going to explore various binary classification algorithms and use `GridSearchCV` to systematically tune the parameters.\n",
    "\n",
    "Using Probably Approximately Correct Learning's terminology, machine learning can be fundamentally decompoased into two subtasks, learning the concept model class and learning the best concept within the class.\n",
    "* The first step is about forming hypothesis about concept class, a family of possible models. The different algoirthm corresponding to different concpet class and hence model selection is about find the best concept class. \n",
    "* Given any concept class, we also need to find the best concept with the class, that is the role of parameter tuning.\n",
    "\n",
    "Any machine learning must performan both steps to achieve any sort of learning. Failed at doing any of two, one will left with a bad model that doesn't generalise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desicison Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "------------------------------------------------------------\n",
      "DecisionTreeClassifier(class_weight={0: 1, 1: 2}, criterion='gini',\n",
      "            max_depth=1, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=0.01, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\n",
      "\n",
      "Performance on Training Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.952     0.898     0.924        88\n",
      "       True      0.500     0.692     0.581        13\n",
      "\n",
      "avg / total      0.894     0.871     0.880       101\n",
      "\n",
      "\n",
      "\n",
      "Performance on Validation Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.902     0.949     0.925        39\n",
      "       True      0.333     0.200     0.250         5\n",
      "\n",
      "avg / total      0.838     0.864     0.848        44\n",
      "\n",
      "\n",
      "\n",
      "Performance on Entire DataSet:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.935     0.913     0.924       127\n",
      "       True      0.476     0.556     0.513        18\n",
      "\n",
      "avg / total      0.878     0.869     0.873       145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decisionTree = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(),            \n",
    "    param_grid = {\n",
    "        'max_depth': range(1, 5),\n",
    "        'min_impurity_split': [0.01, 0.1, 0.3],\n",
    "        'class_weight': ['balanced', { 0: 1, 1: 2 }, { 0: 1, 1: 4 }, { 0: 1, 1: 8 }]\n",
    "    },\n",
    "    scoring='f1',\n",
    ")\n",
    "    \n",
    "report(decisionTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree classifier reports very different performance score under training and validation data set. This model is subject to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianchuanting/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "------------------------------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=1, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_split=0.01,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Performance on Training Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      1.000     0.739     0.850        88\n",
      "       True      0.361     1.000     0.531        13\n",
      "\n",
      "avg / total      0.918     0.772     0.809       101\n",
      "\n",
      "\n",
      "\n",
      "Performance on Validation Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      1.000     0.795     0.886        39\n",
      "       True      0.385     1.000     0.556         5\n",
      "\n",
      "avg / total      0.930     0.818     0.848        44\n",
      "\n",
      "\n",
      "\n",
      "Performance on Entire DataSet:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      1.000     0.756     0.861       127\n",
      "       True      0.367     1.000     0.537        18\n",
      "\n",
      "avg / total      0.921     0.786     0.821       145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=0, n_estimators=10),            \n",
    "    param_grid = {\n",
    "        'max_depth': range(1, 5),\n",
    "        'min_impurity_split': [0.01, 0.1, 0.3],\n",
    "        'class_weight': ['balanced', { 0: 1, 1: 2 }, { 0: 1, 1: 4 }, { 0: 1, 1: 8 }]\n",
    "    },\n",
    "    scoring='f1'\n",
    ")\n",
    "    \n",
    "report(random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This random forest achieves an 100% recall on both test set and validation set. Furthermore, the difference in precision scores using test set and validation set are within 0.03. This model generalise pretty well, and achieved a precision and recall significantly higher than the minimium required 0.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "------------------------------------------------------------\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight={0: 1, 1: 4}, criterion='gini',\n",
      "            max_depth=4, max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=0.1, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "          learning_rate=2, n_estimators=10, random_state=0)\n",
      "\n",
      "\n",
      "Performance on Training Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.976     0.932     0.953        88\n",
      "       True      0.647     0.846     0.733        13\n",
      "\n",
      "avg / total      0.934     0.921     0.925       101\n",
      "\n",
      "\n",
      "\n",
      "Performance on Validation Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.923     0.923     0.923        39\n",
      "       True      0.400     0.400     0.400         5\n",
      "\n",
      "avg / total      0.864     0.864     0.864        44\n",
      "\n",
      "\n",
      "\n",
      "Performance on Entire DataSet:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.959     0.929     0.944       127\n",
      "       True      0.591     0.722     0.650        18\n",
      "\n",
      "avg / total      0.914     0.903     0.908       145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboosting = GridSearchCV(\n",
    "    estimator=AdaBoostClassifier(random_state=0, base_estimator=DecisionTreeClassifier(), n_estimators=10),            \n",
    "    param_grid = {\n",
    "        'base_estimator__min_impurity_split': [0.01, 0.1, 0.3],\n",
    "        'base_estimator__max_depth': range(1, 5),\n",
    "        'base_estimator__class_weight': ['balanced', { 0: 1, 1: 2 }, { 0: 1, 1: 4 }, {0: 1, 1: 8}], \n",
    "        'learning_rate': [1, 2, 4, 6],\n",
    "    },\n",
    "    scoring='f1',\n",
    ")\n",
    "\n",
    "report(adaboosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning the premeters, the model is able to achieve 0.4 for both presion and recall. However, as we can see, those score are quite different than the one reported using training data set. It is likely to surfer from overfitting as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "------------------------------------------------------------\n",
      "Pipeline(steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=0,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('logit', LogisticRegression(C=2, class_weight={0: 1, 1: 30}, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])\n",
      "\n",
      "\n",
      "Performance on Training Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      1.000     0.693     0.819        88\n",
      "       True      0.325     1.000     0.491        13\n",
      "\n",
      "avg / total      0.913     0.733     0.777       101\n",
      "\n",
      "\n",
      "\n",
      "Performance on Validation Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.938     0.769     0.845        39\n",
      "       True      0.250     0.600     0.353         5\n",
      "\n",
      "avg / total      0.859     0.750     0.789        44\n",
      "\n",
      "\n",
      "\n",
      "Performance on Entire DataSet:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.978     0.717     0.827       127\n",
      "       True      0.308     0.889     0.457        18\n",
      "\n",
      "avg / total      0.895     0.738     0.781       145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = Pipeline(steps=[\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA(random_state=0)),\n",
    "    ('logit', LogisticRegression()),\n",
    "])\n",
    "\n",
    "logit = GridSearchCV(\n",
    "    estimator=logit,            \n",
    "    param_grid = {\n",
    "        'pca__n_components': range(1, 6),\n",
    "        'logit__C': [0.1, 0.5, 1, 2, 4, 10, 50],\n",
    "        'logit__tol': [0.0001, 0.1, 1, 10, 100],\n",
    "        'logit__class_weight': [{0: 1, 1: 30}]\n",
    "    },\n",
    "    scoring='f1',\n",
    ")\n",
    "\n",
    "report(logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logitis regression requires independent variables to be independent of each other, which is clearly not the case in our features. Hence, I have transfered data using PCA prior fitting the model. And because PCA is not scale invariant, I have applied additional scaling before passing the data to PCA. I had to force a rather large class weight to postive labels, as my previous attempts with low class weight results zero recall for positive on validation data set, due to the dataset unbalances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "------------------------------------------------------------\n",
      "GaussianNB(priors=None)\n",
      "\n",
      "\n",
      "Performance on Training Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.920     0.920     0.920        88\n",
      "       True      0.462     0.462     0.462        13\n",
      "\n",
      "avg / total      0.861     0.861     0.861       101\n",
      "\n",
      "\n",
      "\n",
      "Performance on Validation Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.886     1.000     0.940        39\n",
      "       True      0.000     0.000     0.000         5\n",
      "\n",
      "avg / total      0.786     0.886     0.833        44\n",
      "\n",
      "\n",
      "\n",
      "Performance on Entire DataSet:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.909     0.945     0.927       127\n",
      "       True      0.462     0.333     0.387        18\n",
      "\n",
      "avg / total      0.854     0.869     0.860       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianchuanting/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "nb = GridSearchCV(\n",
    "    estimator=GaussianNB(),            \n",
    "    param_grid = {},\n",
    "    scoring='f1',\n",
    ")\n",
    "\n",
    "report(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes classifier is performance is pretty bad when comparing to other classifier I have tried. Especially it returns a zero on the valudation set. The model simply doesn't generalise. \n",
    "\n",
    "And different than the logit regression, there is no parameter in Naive Bayes we can tune to improve it performance and counter the effect of the unbalance in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "------------------------------------------------------------\n",
      "Pipeline(steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svm', SVC(C=0.1, cache_size=200, class_weight='balanced', coef0=0,\n",
      "  decision_function_shape=None, degree=1, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "\n",
      "\n",
      "Performance on Training Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.984     0.716     0.829        88\n",
      "       True      0.324     0.923     0.480        13\n",
      "\n",
      "avg / total      0.899     0.743     0.784       101\n",
      "\n",
      "\n",
      "\n",
      "Performance on Validation Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.909     0.769     0.833        39\n",
      "       True      0.182     0.400     0.250         5\n",
      "\n",
      "avg / total      0.826     0.727     0.767        44\n",
      "\n",
      "\n",
      "\n",
      "Performance on Entire DataSet:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.959     0.732     0.830       127\n",
      "       True      0.292     0.778     0.424        18\n",
      "\n",
      "avg / total      0.876     0.738     0.780       145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = Pipeline(steps=[\n",
    "    ('scale', StandardScaler()),\n",
    "    ('svm', SVC(random_state=0)),\n",
    "])\n",
    "\n",
    "svm = GridSearchCV(\n",
    "    estimator=svm,            \n",
    "    param_grid = {\n",
    "        'svm__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'svm__C': [0.01, 0.1, 1, 10],\n",
    "        'svm__degree': range(1, 2, 3),\n",
    "        'svm__coef0': [0, 1, 5, 10],\n",
    "        'svm__gamma': ['auto', 0.1, 1],\n",
    "        'svm__class_weight': ['balanced', {0: 1, 1: 8}, {0: 1, 1: 16}],\n",
    "        'svm__tol': [0.001, 0.1, 1, 5]\n",
    "    },\n",
    "    scoring='f1', \n",
    ")\n",
    "\n",
    "report(svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machine is commonly used for classification problem. \n",
    "\n",
    "Support Vector Machine algorithms are not scale invariant and known to be effective in high dimensional spaces [reference](http://scikit-learn.org/stable/modules/svm.html). Hence, I have used StandardScaler as the preprocessor to transform the data before fitting.\n",
    "\n",
    "However, as it turns out the performance of the fitted model is rather poor on validation set. And the model doesn't generalise very well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "------------------------------------------------------------\n",
      "Pipeline(steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('svm', SVC(C=0.01, cache_size=200, class_weight='balanced', coef0=0,\n",
      "  decision_function_shape=None, degree=1, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True, tol=1,\n",
      "  verbose=False))])\n",
      "\n",
      "\n",
      "Performance on Training Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      1.000     0.614     0.761        88\n",
      "       True      0.277     1.000     0.433        13\n",
      "\n",
      "avg / total      0.907     0.663     0.718       101\n",
      "\n",
      "\n",
      "\n",
      "Performance on Validation Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      1.000     0.641     0.781        39\n",
      "       True      0.263     1.000     0.417         5\n",
      "\n",
      "avg / total      0.916     0.682     0.740        44\n",
      "\n",
      "\n",
      "\n",
      "Performance on Entire DataSet:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      1.000     0.622     0.767       127\n",
      "       True      0.273     1.000     0.429        18\n",
      "\n",
      "avg / total      0.910     0.669     0.725       145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = Pipeline(steps=[\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA()),\n",
    "    ('svm', SVC(random_state=0)),\n",
    "])\n",
    "\n",
    "svm = GridSearchCV(\n",
    "    estimator=svm,            \n",
    "    param_grid = {\n",
    "        'pca__n_components': range(1, 5),\n",
    "        'svm__kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'svm__C': [0.01, 0.1, 1, 10],\n",
    "        'svm__degree': range(1, 2, 3),\n",
    "        'svm__coef0': [0, 1, 5, 10],\n",
    "        'svm__gamma': ['auto', 0.1, 1],\n",
    "        'svm__class_weight': ['balanced', {0: 1, 1: 8}, {0: 1, 1: 16}],\n",
    "        'svm__tol': [0.001, 0.1, 1, 5]\n",
    "    },\n",
    "    scoring='f1', \n",
    ")\n",
    "\n",
    "report(svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the estimator improved signifantly after PCA added to the pipeline. The models seems to generalise quite well. However the precision is still to low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an unbeatable 100% recall, 0.385 precision, and consistent performance across test and validation dataset, the random forest classifier is undoubtly the best estimators among all explored here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance without engineered feautres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "------------------------------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight={0: 1, 1: 8},\n",
      "            criterion='gini', max_depth=2, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_split=0.3,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Performance on Training Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.963     0.875     0.917        88\n",
      "       True      0.476     0.769     0.588        13\n",
      "\n",
      "avg / total      0.900     0.861     0.874       101\n",
      "\n",
      "\n",
      "\n",
      "Performance on Validation Set:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.895     0.872     0.883        39\n",
      "       True      0.167     0.200     0.182         5\n",
      "\n",
      "avg / total      0.812     0.795     0.803        44\n",
      "\n",
      "\n",
      "\n",
      "Performance on Entire DataSet:\n",
      "------------------------------------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.941     0.874     0.906       127\n",
      "       True      0.407     0.611     0.489        18\n",
      "\n",
      "avg / total      0.874     0.841     0.854       145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_random_forest = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=0, n_estimators=10),            \n",
    "    param_grid = {\n",
    "        'max_depth': range(1, 5),\n",
    "        'min_impurity_split': [0.01, 0.1, 0.3],\n",
    "        'class_weight': ['balanced', { 0: 1, 1: 2 }, { 0: 1, 1: 4 }, { 0: 1, 1: 8 }]\n",
    "    },\n",
    "    scoring='f1',\n",
    ")\n",
    "\n",
    "X_train = X_train.drop(['short_term_incomes', 'pct_msg_with_poi'], axis='columns')\n",
    "X_test = X_test.drop(['short_term_incomes', 'pct_msg_with_poi'], axis='columns')\n",
    "X = X.drop(['short_term_incomes', 'pct_msg_with_poi'], axis='columns')\n",
    "\n",
    "_random_forest.fit(X_train, y_train)\n",
    "best = _random_forest.best_estimator_\n",
    "\n",
    "print 'Best estimator:'\n",
    "print '-' * 60\n",
    "print best\n",
    "\n",
    "print '\\n\\nPerformance on Training Set:'\n",
    "print '-' * 60\n",
    "print classification_report(digits=3, y_true=y_train, y_pred=best.predict(X_train))\n",
    "\n",
    "print '\\n\\nPerformance on Validation Set:'\n",
    "print '-' * 60\n",
    "print classification_report(digits=3, y_true=y_test, y_pred=best.predict(X_test))\n",
    "\n",
    "print '\\n\\nPerformance on Entire DataSet:'\n",
    "print '-' * 60\n",
    "print classification_report(digits=3, y_true=y, y_pred=best.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the engineered feature. the performance of our estimator decreased dramatically. The recall decreased from 100% to 20%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Result for Project Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./my_classifier.pkl', 'wb') as fd:\n",
    "    pickle.dump(obj=random_forest, file=fd)\n",
    "    \n",
    "with open('./my_dataset.pkl', 'wb') as fd:\n",
    "    pickle.dump(df.to_dict(orient='index'), file=fd)\n",
    "    \n",
    "with open('./my_feature_list.pkl', 'wb') as fd:\n",
    "    pickle.dump(obj=['poi'] + list_of_features, file=fd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianchuanting/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/tianchuanting/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'min_impurity_split': [0.01, 0.1, 0.3], 'max_depth': [1, 2, 3, 4], 'class_weight': ['balanced', {0: 1, 1: 2}, {0: 1, 1: 4}, {0: 1, 1: 8}]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring='f1', verbose=0)\n",
      "\tAccuracy: 0.81333\tPrecision: 0.36667\tRecall: 0.55000\tF1: 0.44000\tF2: 0.50000\n",
      "\tTotal predictions:  150\tTrue positives:   11\tFalse positives:   19\tFalse negatives:    9\tTrue negatives:  111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
